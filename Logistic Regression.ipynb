{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit,cross_val_score\n",
    "from scipy import optimize as op\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score , roc_curve , auc, classification_report, confusion_matrix, mean_squared_error, explained_variance_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing data\n",
    "def preprocess_hazlenuts():\n",
    "    initialdata = pd.read_csv(\"dataset\\hazlenuts.txt\", delimiter='\\t',encoding='latin1', na_values=\"n/a\", index_col = 0)\n",
    "    hazlenut_data = initialdata.T\n",
    "    hazlenut_data.columns = ['Length','width', 'thickness', 'surface_area', 'mass', 'compactness', 'hardness', 'shell_top_radius', 'water_content', 'carbohydrate_content', 'variety']\n",
    "    hazlenut_data.reset_index(inplace=True)\n",
    "    df = hazlenut_data.drop('index', axis=1)\n",
    "    df.head()\n",
    "    return (df, df.iloc[:,-1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_generic(path):\n",
    "    \"\"\"\n",
    "    Generic method to read any other dataset assuming rows and columns are in correct order\n",
    "    \"\"\"\n",
    "    rawdata = pd.read_csv(path, delimiter='\\t',encoding='latin1', na_values=\"n/a\", index_col = 0)\n",
    "    df = hazlenut_data.drop('index', axis=1)\n",
    "    df.head()\n",
    "    return (df, df.iloc[:,-1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>width</th>\n",
       "      <th>thickness</th>\n",
       "      <th>surface_area</th>\n",
       "      <th>mass</th>\n",
       "      <th>compactness</th>\n",
       "      <th>hardness</th>\n",
       "      <th>shell_top_radius</th>\n",
       "      <th>water_content</th>\n",
       "      <th>carbohydrate_content</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.86</td>\n",
       "      <td>13.0995</td>\n",
       "      <td>7.349906812</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1439.55</td>\n",
       "      <td>0.93401</td>\n",
       "      <td>8.78</td>\n",
       "      <td>4.7844</td>\n",
       "      <td>0.048826089</td>\n",
       "      <td>0.167</td>\n",
       "      <td>c_avellana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.53</td>\n",
       "      <td>15.5925</td>\n",
       "      <td>9.565426582</td>\n",
       "      <td>49.89</td>\n",
       "      <td>1623.3</td>\n",
       "      <td>0.96217</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.2893</td>\n",
       "      <td>0.049521325</td>\n",
       "      <td>0.174</td>\n",
       "      <td>c_americana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.13</td>\n",
       "      <td>12.222</td>\n",
       "      <td>7.182948645</td>\n",
       "      <td>35.43</td>\n",
       "      <td>1412.25</td>\n",
       "      <td>0.90178</td>\n",
       "      <td>13.694</td>\n",
       "      <td>4.8168</td>\n",
       "      <td>0.049594663</td>\n",
       "      <td>0.167</td>\n",
       "      <td>c_avellana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.85</td>\n",
       "      <td>14.724</td>\n",
       "      <td>8.622661318</td>\n",
       "      <td>43.29</td>\n",
       "      <td>1512</td>\n",
       "      <td>0.96261</td>\n",
       "      <td>10.925</td>\n",
       "      <td>4.6296</td>\n",
       "      <td>0.050384315</td>\n",
       "      <td>0.173</td>\n",
       "      <td>c_americana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.11</td>\n",
       "      <td>17.4105</td>\n",
       "      <td>9.680494488</td>\n",
       "      <td>56.25</td>\n",
       "      <td>1698.9</td>\n",
       "      <td>0.98989</td>\n",
       "      <td>11.564</td>\n",
       "      <td>5.3928</td>\n",
       "      <td>0.050905478</td>\n",
       "      <td>0.17</td>\n",
       "      <td>c_cornuta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Length    width    thickness surface_area     mass compactness hardness  \\\n",
       "0  13.86  13.0995  7.349906812         38.1  1439.55     0.93401     8.78   \n",
       "1  20.53  15.5925  9.565426582        49.89   1623.3     0.96217     5.12   \n",
       "2  14.13   12.222  7.182948645        35.43  1412.25     0.90178   13.694   \n",
       "3  15.85   14.724  8.622661318        43.29     1512     0.96261   10.925   \n",
       "4  21.11  17.4105  9.680494488        56.25   1698.9     0.98989   11.564   \n",
       "\n",
       "  shell_top_radius water_content carbohydrate_content      variety  \n",
       "0           4.7844   0.048826089                0.167   c_avellana  \n",
       "1           5.2893   0.049521325                0.174  c_americana  \n",
       "2           4.8168   0.049594663                0.167   c_avellana  \n",
       "3           4.6296   0.050384315                0.173  c_americana  \n",
       "4           5.3928   0.050905478                 0.17    c_cornuta  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Orgaizing data\n",
    "df, classDetails = preprocess_hazlenuts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Samples\n",
    "samples = df.shape[0]\n",
    "\n",
    "#Length of all feature columns\n",
    "n = len(df.columns) - 1\n",
    "\n",
    "#Number of Labels/Classes\n",
    "k = len(classDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initializing an array of 1s as X-features and y-labels using numpys based on the sampling size\n",
    "X = np.ones((samples,n))\n",
    "y = np.array((samples,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting values for X and y with feature values and labels respectively\n",
    "for i in range(1,n):\n",
    "    X[:,i] = df.iloc[:,i-1]\n",
    "    \n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Standard Scaler library Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of Logistic Regression\n",
    "\n",
    "#Sigmoid function based on the mathematical formula\n",
    "def sigmoid(t):\n",
    "    \"\"\"\n",
    "    The logistic Regression is represented by a sigmoid function. Returns probability for a class.\n",
    "    Parameters:\n",
    "        t = exponential power which determines the sigmoid function\n",
    "        input to t would be feature values cross product with theta\n",
    "    \"\"\"\n",
    "    return 1.0 / (1 + np.exp(-t))\n",
    "\n",
    "#Regularized cost function \n",
    "def regularized_cost(theta, X, y, alpha):\n",
    "    \"\"\"\n",
    "    Cost function to determine the performance of a model and represent all values as a single real number.\n",
    "    Parameters:\n",
    "        hypothesis = generates values for the sigmoid function for given X\n",
    "        samples = total number of testing samples\n",
    "        alpha = represents the learning rate of the algorithm\n",
    "    \"\"\"\n",
    "    hypothesis = sigmoid(X.dot(theta)) \n",
    "    cost = (1 / samples) * (-y.T.dot(np.log(hypothesis)) - (1 - y).T.dot(np.log(1 - hypothesis))) + (alpha/(2 * samples)) * np.sum(theta**2)\n",
    "    return cost\n",
    "\n",
    "#Regularized gradient function\n",
    "def regularized_gradient_descend(theta, X, y, alpha):\n",
    "    \"\"\"\n",
    "    Gradient Descend function to find the optimal minimal point\n",
    "    Parameters:\n",
    "        m = number of samples\n",
    "        n = number of feature columns\n",
    "        theta = vector of zeros\n",
    "        hypothesis = generates values for a sigmoid function for given X\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = theta.reshape((n, 1))\n",
    "    y = y.reshape((m, 1))\n",
    "    hypothesis = sigmoid(X.dot(theta))\n",
    "    return ((1 / m) * X.T.dot(hypothesis - y)) + (alpha * theta /m)\n",
    "\n",
    "#Optimal theta calculation\n",
    "def logistic_regression(X, y, theta, no_of_iterations, alpha):\n",
    "    \"\"\"\n",
    "    Calculating optimal theta value.\n",
    "    Parameters:\n",
    "        no_of_iterations = total number of iterations to calculate the optimal theta value default value is 10000\n",
    "        alpha = learning rate of the model default value is 0.01\n",
    "        X = Stadardized feature values\n",
    "        y = Class Train set\n",
    "    \"\"\"\n",
    "    cost_arr = []\n",
    "    for i in range(no_of_iterations):\n",
    "        cost = regularized_cost(theta, X, y, alpha)\n",
    "        cost = cost.sum(axis = 0)\n",
    "        new_theta = regularized_gradient_descend(theta, X, y, alpha)\n",
    "        theta = theta - new_theta  \n",
    "        cost_arr.append(cost)\n",
    "    return theta, cost_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Sigmoid \n",
    "a = np.arange(-10., 10., 0.2)\n",
    "re = []\n",
    "for zz in a:\n",
    "    sig = sigmoid(zz)\n",
    "    re.append(sig)\n",
    "plt.plot(a,re)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def one_versus_all_encoding(classDetails, X_train, y_train, no_of_iterations, alpha):\n",
    "    \"\"\"\n",
    "    Using One vs All encoding to find the optimal theta values for each class \n",
    "    \"\"\"\n",
    "    all_theta = np.zeros((k, n))\n",
    "    i = 0\n",
    "    for variety in classDetails:\n",
    "        tmp_y = np.array(y_train == variety, dtype = int)\n",
    "        optTheta, cost = logistic_regression(X_train, tmp_y, np.zeros((n,1)), no_of_iterations, alpha)\n",
    "        all_theta[i] = optTheta.T\n",
    "        i += 1\n",
    "        #print(cost)\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_score_predictions(X_train, X_test, y_train, y_test, no_of_iterations = 10000, alpha = 0.001):\n",
    "    \"\"\"\n",
    "    This method predicts all the probability and returns the accuracy score\n",
    "    Parameters:\n",
    "        predictions = Contatins the list of predicted classes\n",
    "        my_score = accuracy score of my model\n",
    "    \"\"\"\n",
    "    #Optimal theta calculation for all classes\n",
    "    all_theta = one_versus_all_encoding(classDetails, X_train, y_train, no_of_iterations, alpha)\n",
    "\n",
    "    #Calculating all probabilities based on the theta values\n",
    "    all_probabilites = sigmoid(X_test.dot(all_theta.T))\n",
    "\n",
    "    #Assigning class labels based on the maximum probabilites coefficients calculated\n",
    "    predictions = [classDetails[np.argmax(all_probabilites[i, :])] for i in range(X_test.shape[0])]\n",
    "    my_score = accuracy_score(y_test, predictions) * 100\n",
    "    return predictions, my_score, all_probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_cross_validation(iterations=10):\n",
    "    \"\"\"\n",
    "    Method to cross validate the predictions by shuffling the train test split\n",
    "    Returns best fit for train test split along with the accuracy scores of the constructed model with scikit\n",
    "    \"\"\"\n",
    "    model = linear_model.LogisticRegression(multi_class='auto')\n",
    "    my_model = []\n",
    "    scikit_model = []\n",
    "    for i in range(iterations):\n",
    "    #Splitting the train and test cases in the ratio of 1/3\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n",
    "\n",
    "        predictions, my_score, all_probabilites = lr_score_predictions(X_train, X_test, y_train, y_test)\n",
    "        #Priting accuracy of the model\n",
    "        print(\"My Model Test Accuracy for run \", i+1, \" \", my_score , '%')\n",
    "        my_model.append(my_score)\n",
    "        if len(my_model) == 1:\n",
    "            optX_train = X_train\n",
    "            optX_test = X_test\n",
    "            opty_train = y_train\n",
    "            opty_test = y_test\n",
    "            score = my_model[-1]\n",
    "        else:\n",
    "            if my_model[-1] >= max(my_model):\n",
    "                optX_train = X_train\n",
    "                optX_test = X_test\n",
    "                opty_train = y_train\n",
    "                opty_test = y_test\n",
    "                score = my_model[-1]\n",
    "           \n",
    "        #Scikit learn model fit and predict\n",
    "        model.fit(X_train,y_train)\n",
    "        model_prediction = model.predict(X_test)\n",
    "        scikit_score = accuracy_score(y_test, model_prediction) * 100\n",
    "        print(\"Scikit Test Accuracy for run \", i+1, \" \", scikit_score , '%')\n",
    "        scikit_model.append(scikit_score)\n",
    "    print(\"My Model Overall Test Accuracy \", statistics.mean(my_model) , '%')\n",
    "    print(\"Scikit Model Overall Test Accuracy \", statistics.mean(scikit_model) , '%')\n",
    "    return optX_train, optX_test, opty_train, opty_test, score, all_probabilites    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Model Test Accuracy for run  1   92.42424242424242 %\n",
      "Scikit Test Accuracy for run  1   90.9090909090909 %\n",
      "My Model Test Accuracy for run  2   96.96969696969697 %\n",
      "Scikit Test Accuracy for run  2   90.9090909090909 %\n",
      "My Model Test Accuracy for run  3   95.45454545454545 %\n",
      "Scikit Test Accuracy for run  3   92.42424242424242 %\n",
      "My Model Test Accuracy for run  4   95.45454545454545 %\n",
      "Scikit Test Accuracy for run  4   87.87878787878788 %\n",
      "My Model Test Accuracy for run  5   96.96969696969697 %\n",
      "Scikit Test Accuracy for run  5   90.9090909090909 %\n",
      "My Model Test Accuracy for run  6   95.45454545454545 %\n",
      "Scikit Test Accuracy for run  6   86.36363636363636 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, score, all_probablities = test_lr_cross_validation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best fit test set\n",
    "predictions, my_score, all_probablities = lr_score_predictions(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSV(predictions, y_test):\n",
    "    \"\"\"\n",
    "    Creates a CSV file with actual predictions and model predicted values\n",
    "    \"\"\"\n",
    "    overall=[]\n",
    "    for i in range(len(predictions)):\n",
    "        overall.append([predictions[i], y_test.values[i], 'Matched' if predictions[i] == y_test.values[i] else 'Unmatched'])\n",
    "        Result = pd.DataFrame(overall, columns=[\"Predicted Values\", \"Actual Value\", \"Matched/Unmatched\"])\n",
    "    Result.to_csv('Output.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createCSV(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred , all_probablities, average=\"macro\",classes=k):\n",
    "    \"\"\"\n",
    "    This method returns the ROC score.\n",
    "    Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    \"\"\"\n",
    "    y_test = list(y_test)\n",
    "    y_pred = list(y_pred)\n",
    "    label = LabelBinarizer()\n",
    "    label.fit(y_test)\n",
    "    y_test = label.transform(y_test)\n",
    "    y_pred = label.transform(y_pred)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(classes):\n",
    "        y_ = [y[i] for y in all_probablities ]\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return roc_auc_score(y_test, y_pred, average=average) , (fpr,tpr,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_roc(fpr, tpr, roc):\n",
    "    \"\"\"\n",
    "    This method is used for Plotting ROC for all classes\n",
    "    Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    \"\"\"\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(k)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(k):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= k\n",
    "    for i in range(k):\n",
    "        plt.plot(fpr[i],tpr[i],label='ROC = for %s %s' % (classDetails[i] , roc[i] * 100))\n",
    "    \n",
    "    plt.legend(loc=\"top right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_roc , micro_additional_roc  = multiclass_roc_auc_score(y_test, predictions ,all_probablities, average=\"micro\")\n",
    "roc , additional_roc  = multiclass_roc_auc_score(y_test, predictions ,all_probablities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Micro Average ROC calculation', micro_roc)\n",
    "print('Macro Average ROC calculation', roc)\n",
    "print('Accuracy', my_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for my model', classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc = additional_roc\n",
    "plotting_roc(fpr, tpr, roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_test, predictions, labels = classDetails)\n",
    "sns.heatmap(cfm, annot = True, xticklabels = classDetails, yticklabels = classDetails);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting ROC for Scikit model\n",
    "model = linear_model.LogisticRegression(multi_class='auto')\n",
    "model.fit(X_train,y_train)\n",
    "model_prediction = model.predict(X_test)\n",
    "pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_scikit_roc , micro_scikit_additional_roc  = multiclass_roc_auc_score(y_test, model_prediction ,pred, average=\"micro\")\n",
    "scikit_roc , scikit_additional_roc  = multiclass_roc_auc_score(y_test, model_prediction ,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Micro Average ROC calculation', micro_scikit_roc)\n",
    "print('Macro Average ROC calculation', scikit_roc)\n",
    "print('Accuracy', accuracy_score(y_test, model_prediction)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for scikit model', classification_report(y_test,model_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc = scikit_additional_roc\n",
    "m_fpr, m_tpr, m_roc = micro_scikit_additional_roc\n",
    "plotting_roc(fpr, tpr, roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_test, model_prediction, labels = classDetails)\n",
    "sns.heatmap(cfm, annot = True, xticklabels = classDetails, yticklabels = classDetails);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
